{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2de0ed9d-4868-46ec-bce3-be96678759ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchcde\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from lsde_model import LSDE\n",
    "from lnsde_model import LNSDE\n",
    "from gsde_model import GSDE\n",
    "from sde_model import SDE\n",
    "from ode_model import ODE\n",
    "from cde_model import CDE\n",
    "from rnn_model import RNN\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utilities import collate_fn, create_dataloaders, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c5d79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc8dc1",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18d52c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "\n",
    "input_dim = 3 # [t, x, y]\n",
    "output_dim = 2 # [x, y]\n",
    "n_classes = 8\n",
    "\n",
    "num_epochs = 1000\n",
    "val_every = 1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b029d6b",
   "metadata": {},
   "source": [
    "### Train and test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bc10373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    ts = torch.linspace(0, 1, batch.size(1), device=device) # Time steps\n",
    "    ts_expanded = ts.unsqueeze(0).unsqueeze(-1).expand(batch.size(0), -1, -1) # (batch_size, seq_len, 1)\n",
    "    batch = torch.cat((ts_expanded, batch), dim=-1) # Concatenate time steps and batch coordinates (batch_size, seq_len, 3)\n",
    "\n",
    "        # Coefficients of a continuous representation of discrete data\n",
    "    coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(batch, ts)\n",
    "    return batch, ts, coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9bb6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_step(model, dataloader, optimizer, scheduler, train=True, rnn=False):\n",
    "    if train: model.train()\n",
    "    else: model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    correct_fix_preds = 0\n",
    "    n_fixs = 0\n",
    "    for sbj_ids, _, batch, mask in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        sbj_ids = sbj_ids.to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        batch, ts, coeffs = process_batch(batch)\n",
    "\n",
    "        if train: optimizer.zero_grad()\n",
    "\n",
    "        if rnn:\n",
    "            _, logits = model(batch, mask)\n",
    "        else:\n",
    "            _, logits = model(coeffs, ts, mask)\n",
    "        loss = criterion(logits, sbj_ids)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct_fix_preds += (preds == sbj_ids).sum().item()\n",
    "        n_fixs += len(sbj_ids)\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    if not train: scheduler.step(epoch_loss)\n",
    "    epoch_accuracy = correct_fix_preds / n_fixs\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d78fb7a8-b2a0-4289-841c-95489c81e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, scheduler, early_stopping, model_name, rnn=False):\n",
    "    os.makedirs(model_name.split('_')[0], exist_ok=True)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_epoch = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    epoch_bar = tqdm(range(1, num_epochs + 1), desc=\"Epochs\")\n",
    "    for epoch in epoch_bar:\n",
    "        # Train step\n",
    "        epoch_train_loss, _ = train_val_step(model, train_loader, optimizer, scheduler, train=True, rnn=rnn)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        # Val step\n",
    "        if epoch % val_every == 0:\n",
    "            epoch_val_loss, epoch_accuracy = train_val_step(model, val_loader, optimizer, scheduler, train=False, rnn=rnn)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "\n",
    "            # Save best model\n",
    "            if epoch_val_loss < best_val_loss:\n",
    "                best_epoch = epoch\n",
    "                best_val_loss = epoch_val_loss\n",
    "                best_accuracy = epoch_accuracy\n",
    "                epoch_bar.set_postfix({\"Best Epoch\": best_epoch, \"Best Val Loss\": round(best_val_loss, 3), \"Accuracy\": round(best_accuracy, 3)})\n",
    "                torch.save({\n",
    "                    'model': model.state_dict(),\n",
    "                    'epoch': best_epoch,\n",
    "                    'val_loss': best_val_loss,\n",
    "                    'val_accuracy': best_accuracy\n",
    "                }, f\"{model_name.split('_')[0]}/{model_name}_best_model.pth\")\n",
    "\n",
    "            early_stopping(epoch_val_loss)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"\\tEarly stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{model_name.split('_')[0]}/{model_name}_losses.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    return best_epoch, best_val_loss, best_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea22e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, rnn=False):\n",
    "    model.eval()\n",
    "\n",
    "    scanpath_preds = defaultdict(list)  # scanpath_id -> [pred1, pred2, ...]\n",
    "    scanpath_labels = {}                # scanpath_id -> label\n",
    "\n",
    "    correct_fix_preds = 0\n",
    "    n_fixs = 0\n",
    "    with torch.no_grad():\n",
    "        for sbj_ids, scanpaths_ids, batch, mask in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            sbj_ids = sbj_ids.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            batch, ts, coeffs = process_batch(batch)\n",
    "\n",
    "            if rnn:\n",
    "                _, logits = model(batch, mask)\n",
    "            else:\n",
    "                _, logits = model(coeffs, ts, mask)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct_fix_preds += (preds == sbj_ids).sum().item()\n",
    "            n_fixs += len(sbj_ids)\n",
    "\n",
    "            for scanpath_id, true, pred in zip(scanpaths_ids, sbj_ids, preds.cpu().tolist()):\n",
    "                scanpath_id = int(scanpath_id)\n",
    "                scanpath_preds[scanpath_id].append(int(pred))\n",
    "                scanpath_labels[scanpath_id] = int(true)\n",
    "\n",
    "    # Majority voting\n",
    "    correct_scanpath_preds = 0\n",
    "    for scanpath_id, preds in scanpath_preds.items():\n",
    "        majority_pred = Counter(preds).most_common(1)[0][0]\n",
    "        if majority_pred == scanpath_labels.get(scanpath_id):\n",
    "            correct_scanpath_preds += 1\n",
    "\n",
    "    fix_accuracy = correct_fix_preds / len(test_loader.dataset)\n",
    "    scanpath_accuracy = correct_scanpath_preds / len(scanpath_preds)\n",
    "\n",
    "    print(f\"Fixations classification: {correct_fix_preds}/{n_fixs} -> {fix_accuracy:.3f}\")\n",
    "    print(f\"Scanpath classification: {correct_scanpath_preds}/{len(scanpath_preds)} -> {scanpath_accuracy:.3f}\")\n",
    "\n",
    "    return fix_accuracy, scanpath_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f5b479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(data, data_type):\n",
    "    batch_sizes = [32, 64, 128]\n",
    "    hidden_dims = [32, 64, 128]\n",
    "\n",
    "    os.makedirs(f\"{data_type}_models\", exist_ok=True)\n",
    "    os.chdir(f\"{data_type}_models\")\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "\n",
    "        train_loader, val_loader, test_loader = create_dataloaders(data, train_size, val_size, batch_size, data_type)\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "\n",
    "            models = {\n",
    "                \"rnn\": RNN(input_dim, hidden_dim, output_dim, n_classes, rnn_type=\"rnn\").to(device),\n",
    "                \"gru\": RNN(input_dim, hidden_dim, output_dim, n_classes, rnn_type=\"gru\").to(device),\n",
    "                \"lstm\": RNN(input_dim, hidden_dim, output_dim, n_classes, rnn_type=\"lstm\").to(device),\n",
    "                \"ncde\": CDE(input_dim, hidden_dim, output_dim, n_classes).to(device),\n",
    "                \"node\": ODE(input_dim, hidden_dim, output_dim, n_classes).to(device),\n",
    "                \"nsde\": SDE(input_dim, hidden_dim, output_dim, n_classes).to(device),\n",
    "                \"lsde\": LSDE(input_dim, hidden_dim, output_dim, n_classes).to(device),\n",
    "                \"lnsde\": LNSDE(input_dim, hidden_dim, output_dim, n_classes).to(device),\n",
    "                \"gsde\": GSDE(input_dim, hidden_dim, output_dim, n_classes).to(device)\n",
    "            }\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                os.makedirs(model_name, exist_ok=True)\n",
    "                optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10)\n",
    "                early_stopping = EarlyStopping(patience=20, delta=1e-3)\n",
    "\n",
    "                tag = f\"{model_name}_bs{batch_size}_hd{hidden_dim}\"\n",
    "\n",
    "                print(f\"Training {tag}...\")\n",
    "                rnn = model_name in {'rnn', 'gru', 'lstm'}\n",
    "                best_epoch, best_val_loss, best_accuracy = train(model, train_loader, val_loader,\n",
    "                                                                 optimizer, scheduler, early_stopping,\n",
    "                                                                 tag, rnn)\n",
    "                print()\n",
    "\n",
    "                print(f\"Testing {tag}...\")\n",
    "                checkpoint = torch.load(f\"{model_name}/{tag}_best_model.pth\")\n",
    "                model.load_state_dict(checkpoint['model'])\n",
    "                test_fix_accuracy, test_scanpath_accuracy = test(model, test_loader, rnn)\n",
    "                print()\n",
    "\n",
    "                stats = {\n",
    "                    \"tag\": tag,\n",
    "                    \"epoch\": best_epoch,\n",
    "                    \"val_loss\": best_val_loss,\n",
    "                    \"val_accuracy\": best_accuracy,\n",
    "                    \"test_accuracy\": test_fix_accuracy,\n",
    "                    \"scanpath_accuracy\": test_scanpath_accuracy,\n",
    "                }\n",
    "\n",
    "                with open(f\"{model_name}/{tag}_stats.json\", \"w\") as f:\n",
    "                    json.dump(stats, f, indent=2)\n",
    "\n",
    "                print()\n",
    "\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb743f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_name, data, batch_size, hidden_dim, k_folds=5):\n",
    "    rnn = model_name in {'rnn', 'gru', 'lstm'}\n",
    "\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    fix_accuracies = []\n",
    "    scanpath_accuracies = []\n",
    "\n",
    "    n_scanpaths = len(data)\n",
    "    scanpath_ids = np.arange(n_scanpaths)\n",
    "    scanpath_labels = np.array([sbj_id for sbj_id, _, _, _ in data])\n",
    "\n",
    "    cv = StratifiedGroupKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold, (train_sp_idxs, test_sp_idxs) in enumerate(cv.split(\n",
    "        X=np.zeros(n_scanpaths),\n",
    "        y=scanpath_labels,\n",
    "        groups=scanpath_ids)):\n",
    "\n",
    "        print(f'Fold {fold + 1}')\n",
    "        model = LSDE(input_dim, hidden_dim, output_dim, n_classes).to(device)\n",
    "\n",
    "        train_fix_data = [\n",
    "            (sbj_id, sp_id, fix)\n",
    "            for sp_id in train_sp_idxs\n",
    "            for sbj_id, _, fixs, _ in [data[sp_id]]\n",
    "            for fix in fixs\n",
    "        ]\n",
    "\n",
    "        test_fix_data = [\n",
    "            (sbj_id, sp_id, fix)\n",
    "            for sp_id in test_sp_idxs\n",
    "            for sbj_id, _, fixs, _ in [data[sp_id]]\n",
    "            for fix in fixs\n",
    "        ]\n",
    "        \n",
    "        train_loader = DataLoader(train_fix_data, batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        test_loader = DataLoader(test_fix_data, batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10)\n",
    "        early_stopping = EarlyStopping(patience=20, delta=1e-3)\n",
    "\n",
    "        best_epoch, best_loss, best_accuracy = train(model, train_loader, test_loader,\n",
    "                                                        optimizer, scheduler, early_stopping,\n",
    "                                                        model_name, rnn)\n",
    "        epochs.append(best_epoch)\n",
    "        losses.append(best_loss)\n",
    "        fix_accuracies.append(best_accuracy)\n",
    "\n",
    "        checkpoint = torch.load(f\"{model_name}/{model_name}_best_model.pth\")\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        _, test_scanpath_accuracy = test(model, test_loader, rnn)\n",
    "        scanpath_accuracies.append(test_scanpath_accuracy)\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(\"Cross validation averages:\")\n",
    "    print(\"\\tEpoch: \", np.mean(epochs))\n",
    "    print(\"\\tVal Loss: \", np.mean(losses))\n",
    "    print(\"\\tVal Fix Accuracy: \", np.mean(fix_accuracies))\n",
    "    print(\"\\tTest Scanpath Accuracy: \", np.mean(scanpath_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1d703",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a666df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scanpaths_fixs_sacs.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f) # list of tuples (sbj_id, scanpath, fixs_list, sacs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3376923",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f23e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  12%|█▏        | 117/1000 [4:17:22<32:22:21, 131.98s/it, Best Epoch=98, Best Val Loss=1.41, Accuracy=0.475]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEarly stopping triggered at epoch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixations classification: 1029/2179 -> 0.472\n",
      "Scanpath classification: 213/320 -> 0.666\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  21%|██▏       | 213/1000 [7:44:50<28:37:32, 130.94s/it, Best Epoch=194, Best Val Loss=1.29, Accuracy=0.537]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEarly stopping triggered at epoch 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixations classification: 1175/2184 -> 0.538\n",
      "Scanpath classification: 241/320 -> 0.753\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  12%|█▏        | 121/1000 [4:24:08<31:58:48, 130.98s/it, Best Epoch=102, Best Val Loss=1.41, Accuracy=0.492]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEarly stopping triggered at epoch 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixations classification: 1072/2179 -> 0.492\n",
      "Scanpath classification: 202/320 -> 0.631\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  14%|█▎        | 136/1000 [4:57:17<31:28:41, 131.16s/it, Best Epoch=117, Best Val Loss=1.32, Accuracy=0.5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEarly stopping triggered at epoch 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixations classification: 1092/2193 -> 0.498\n",
      "Scanpath classification: 220/320 -> 0.688\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  16%|█▌        | 155/1000 [5:37:52<30:41:59, 130.79s/it, Best Epoch=136, Best Val Loss=1.3, Accuracy=0.534] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEarly stopping triggered at epoch 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixations classification: 1176/2194 -> 0.536\n",
      "Scanpath classification: 234/320 -> 0.731\n",
      "\n",
      "Cross validation averages:\n",
      "\tEpoch:  129.4\n",
      "\tVal Loss:  1.345902970177787\n",
      "\tVal Fix Accuracy:  0.5075093268967994\n",
      "\tTest Fix Accuracy:  0.5072325470459766\n",
      "\tTest Scanpath Accuracy:  0.69375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "hidden_dim = 64\n",
    "222\n",
    "model_name = \"lsde\"\n",
    "cross_validation(model_name, data, batch_size, hidden_dim, k_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015eeb2f",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(data, \"fix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e845cfbf",
   "metadata": {},
   "source": [
    "### Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"lsde_bs64_hd128_best_model.pth\"\n",
    "checkpoint = torch.load(model_path)\n",
    "print(checkpoint['epoch'], checkpoint['val_loss'], checkpoint['val_accuracy'])\n",
    "\n",
    "batch_size = 64\n",
    "hidden_dim = 64\n",
    "model = LSDE(input_dim, hidden_dim, output_dim, n_classes).to(device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(data, train_size, val_size, batch_size, \"fix\")\n",
    "test(model, val_loader, rnn=False)\n",
    "test(model, test_loader, rnn=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
